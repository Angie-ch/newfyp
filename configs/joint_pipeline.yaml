# Complete Pipeline Configuration
# Trains both joint autoencoder and diffusion model sequentially

data:
  data_dir: "data/processed_temporal_split"
  past_frames: 8
  future_frames: 12
  era5_channels: 64

model:
  # Joint autoencoder
  era5_channels: 64
  latent_channels: 8
  hidden_dims: [64, 128, 256, 256]
  use_attention: true
  
  # Diffusion model
  hidden_dim: 256
  num_heads: 8
  depth: 3
  use_physics: true
  use_spiral_attention: true
  use_multiscale_temporal: true

training:
  # Stage 1: Autoencoder
  autoencoder:
    epochs: 50
    batch_size: 8
    learning_rate: 1.0e-4
    weight_decay: 0.01
    gradient_clip: 1.0
    era5_weight: 1.0
    track_weight: 10.0
    intensity_weight: 5.0
    log_dir: "logs/joint_autoencoder"
    save_dir: "checkpoints/joint_autoencoder"
  
  # Stage 2: Diffusion
  diffusion:
    epochs: 100
    batch_size: 4
    learning_rate: 2.0e-4
    weight_decay: 0.01
    gradient_clip: 1.0
    timesteps: 1000
    beta_start: 1.0e-4
    beta_end: 0.02
    beta_schedule: "linear"
    ema_decay: 0.9999
    log_dir: "logs/joint_diffusion"
    save_dir: "checkpoints/joint_diffusion"
    
    loss_weights:
      diffusion: 1.0
      track: 0.5
      intensity: 0.3
      physics: 0.2
      consistency: 0.1
    
    physics_weights:
      energy: 0.3
      momentum: 0.3
      vorticity: 0.4
  
  # Common settings
  log_interval: 50
  save_interval: 5
  num_workers: 4

